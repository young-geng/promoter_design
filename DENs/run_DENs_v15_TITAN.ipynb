{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f718dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e886489",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_configs = []\n",
    "all_configs.append({\n",
    "    \"diversity_loss_coef\": 1.0,\n",
    "    \"entropy_loss_coef\": 1.0,\n",
    "    \"base_entropy_loss_coef\": 5.0,\n",
    "})\n",
    "all_configs.append({\n",
    "    \"diversity_loss_coef\": 5.0,\n",
    "    \"entropy_loss_coef\": 1.0,\n",
    "    \"base_entropy_loss_coef\": 5.0,\n",
    "})\n",
    "all_configs.append({\n",
    "    \"diversity_loss_coef\": 10.0,\n",
    "    \"entropy_loss_coef\": 1.0,\n",
    "    \"base_entropy_loss_coef\": 10.0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae71a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 14982988\n",
      "sbatch --requeue --export=scripts_dir=/global/home/users/aniketh/promoter/,pretrained_predictor_path=/global/scratch/users/aniketh/promoter_modelling/jax_data/trained_predictors_final/coms_0.0_THP1_weight_1.5.pkl,diff_exp_cell_ind=1,diversity_loss_coef=1.0,entropy_loss_coef=1.0,base_entropy_loss_coef=5.0,oracle_test_data_path=/global/scratch/users/aniketh/promoter_modelling/jax_data/finetune_data.pkl,saved_models_dir=/global/scratch/users/aniketh/promoter_modelling/jax_data/saved_DEN_models_v15_TITAN,wandb_dir=/global/scratch/users/aniketh/promoter_modelling/jax_data/wandb_v15_TITAN,experiment_id=Jurkat_using_coms_0.0_THP1_weight_1.5.pkl_div_coef_1.0_ent_coef_1.0_bent_coef_5.0 run_DENs_v15_TITAN.sh\n",
      "\n",
      "export scripts_dir=/global/home/users/aniketh/promoter/\n",
      "export pretrained_predictor_path=/global/scratch/users/aniketh/promoter_modelling/jax_data/trained_predictors_final/coms_0.0_THP1_weight_1.5.pkl\n",
      "export diff_exp_cell_ind=1\n",
      "export diversity_loss_coef=1.0\n",
      "export entropy_loss_coef=1.0\n",
      "export base_entropy_loss_coef=5.0\n",
      "export oracle_test_data_path=/global/scratch/users/aniketh/promoter_modelling/jax_data/finetune_data.pkl\n",
      "export saved_models_dir=/global/scratch/users/aniketh/promoter_modelling/jax_data/saved_DEN_models_v15_TITAN\n",
      "export wandb_dir=/global/scratch/users/aniketh/promoter_modelling/jax_data/wandb_v15_TITAN\n",
      "export experiment_id=Jurkat_using_coms_0.0_THP1_weight_1.5.pkl_div_coef_1.0_ent_coef_1.0_bent_coef_5.0\n",
      "bash /global/home/users/aniketh/promoter/promoter/run_DENs_v15_TITAN.sh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jax_data_dir = \"/global/scratch/users/aniketh/promoter_modelling/jax_data/\"\n",
    "scripts_dir = \"/global/home/users/aniketh/promoter/\"\n",
    "\n",
    "oracle_test_data_path = os.path.join(jax_data_dir, \"finetune_data.pkl\")\n",
    "assert os.path.exists(oracle_test_data_path)\n",
    "\n",
    "saved_models_dir = os.path.join(jax_data_dir, \"saved_DEN_models_v15_TITAN\")\n",
    "if not os.path.exists(saved_models_dir):\n",
    "    os.mkdir(saved_models_dir)\n",
    "assert os.path.exists(saved_models_dir)\n",
    "\n",
    "wandb_dir = os.path.join(jax_data_dir, \"wandb_v15_TITAN\")\n",
    "if not os.path.exists(wandb_dir):\n",
    "    os.mkdir(wandb_dir)\n",
    "assert os.path.exists(wandb_dir)\n",
    "\n",
    "bash_scripts_dir = \"/global/home/users/aniketh/promoter/promoter/run_DENs_v15_TITAN_bash_scripts\"\n",
    "if not os.path.exists(bash_scripts_dir):\n",
    "    os.mkdir(bash_scripts_dir)\n",
    "    \n",
    "total_count = len(os.listdir(os.path.join(jax_data_dir, \"trained_predictors_final\"))) * len([\"THP1\", \"Jurkat\", \"K562\"]) * len(all_configs)\n",
    "\n",
    "num_splits = 1\n",
    "runs_per_job = int(np.ceil(total_count / num_splits))\n",
    "job_cnt = 0\n",
    "cur_cnt = 0\n",
    "\n",
    "slurm_prefix = open(\"slurm_prefix.txt\", \"r\").readlines()\n",
    "\n",
    "g = open(os.path.join(bash_scripts_dir, f\"train_all_DENs_j{job_cnt}.sh\"), \"w+\")\n",
    "for line in slurm_prefix:\n",
    "    g.write(line)\n",
    "    \n",
    "rem_count = 0\n",
    "\n",
    "flag = False\n",
    "for model in sorted(os.listdir(os.path.join(jax_data_dir, \"trained_predictors_final\"))):\n",
    "    for diff_exp_cell_ind, cell in enumerate([\"THP1\", \"Jurkat\", \"K562\"]):\n",
    "        for config in all_configs:\n",
    "            if flag:\n",
    "                break\n",
    "                \n",
    "            diversity_loss_coef = config[\"diversity_loss_coef\"]\n",
    "            entropy_loss_coef = config[\"entropy_loss_coef\"]\n",
    "            base_entropy_loss_coef = config[\"base_entropy_loss_coef\"]\n",
    "            \n",
    "            experiment_id = f\"{cell}_using_{model}_div_coef_{diversity_loss_coef}_ent_coef_{entropy_loss_coef}_bent_coef_{base_entropy_loss_coef}\"\n",
    "            pretrained_predictor_path = os.path.join(jax_data_dir, \"trained_predictors_final\", model)\n",
    "            \n",
    "            if os.path.exists(os.path.join(saved_models_dir, experiment_id, \"final_sequences.npy\")):\n",
    "                continue\n",
    "                \n",
    "            rem_count += 1\n",
    "        \n",
    "            if cur_cnt == runs_per_job:\n",
    "                job_cnt += 1\n",
    "                cur_cnt = 0\n",
    "                g.close()\n",
    "                g = open(os.path.join(bash_scripts_dir, f\"train_all_DENs_j{job_cnt}.sh\"), \"w+\")\n",
    "                for line in slurm_prefix:\n",
    "                    g.write(line)\n",
    "                print(\"Created new job split\")\n",
    "\n",
    "            cmd = f\"sbatch --requeue --export=scripts_dir={scripts_dir},pretrained_predictor_path={pretrained_predictor_path},diff_exp_cell_ind={diff_exp_cell_ind},diversity_loss_coef={diversity_loss_coef},entropy_loss_coef={entropy_loss_coef},base_entropy_loss_coef={base_entropy_loss_coef},oracle_test_data_path={oracle_test_data_path},saved_models_dir={saved_models_dir},wandb_dir={wandb_dir},experiment_id={experiment_id} run_DENs_v15_TITAN.sh\"\n",
    "            os.system(cmd)\n",
    "            print(cmd)\n",
    "            print()\n",
    "\n",
    "            f = open(os.path.join(bash_scripts_dir, experiment_id + \".sh\"), \"w+\")\n",
    "            f.write(\"#!/bin/bash\\n\")\n",
    "            all_exports = f\"scripts_dir={scripts_dir},pretrained_predictor_path={pretrained_predictor_path},diff_exp_cell_ind={diff_exp_cell_ind},diversity_loss_coef={diversity_loss_coef},entropy_loss_coef={entropy_loss_coef},base_entropy_loss_coef={base_entropy_loss_coef},oracle_test_data_path={oracle_test_data_path},saved_models_dir={saved_models_dir},wandb_dir={wandb_dir},experiment_id={experiment_id}\"\n",
    "            for ex in all_exports.split(\",\"):\n",
    "                var, val = ex.split(\"=\")\n",
    "                print(f\"export {var}={val}\")\n",
    "                f.write(f\"export {var}={val}\\n\")\n",
    "            print(\"bash {}\".format(os.path.join(scripts_dir, \"promoter/run_DENs_v15_TITAN.sh\")))\n",
    "            f.write(\"bash {}\\n\".format(os.path.join(scripts_dir, \"promoter/run_DENs_v15_TITAN.sh\")))\n",
    "            f.close()\n",
    "\n",
    "            g.write(\"bash {}\".format(os.path.join(bash_scripts_dir, experiment_id + \".sh\\n\")))        \n",
    "            print()\n",
    "\n",
    "            cur_cnt += 1\n",
    "            \n",
    "#             if rem_count == 16:\n",
    "#                 print(\"Submitting only 16 jobs\")\n",
    "#                 flag = True\n",
    "                \n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3971a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c813c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaa384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mar312023",
   "language": "python",
   "name": "mar312023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
